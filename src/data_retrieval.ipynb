{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPYhlQj9CG2i+t4QNfIaXe4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bhekmuzi/water-usage-norm/blob/main/src/data_retrieval.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip freeze > requirements.txt"
      ],
      "metadata": {
        "id": "tn2hJoUBYdoc"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install influxdb"
      ],
      "metadata": {
        "id": "N-bFSmf9YmhF"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install pandas pymongo"
      ],
      "metadata": {
        "id": "uzwCwKVcZPC4"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "qih7MD7MTfH8"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.cluster import KMeans\n",
        "# pip install influxdb\n",
        "# !python --version\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import datetime\n",
        "import time\n",
        "from influxdb import InfluxDBClient\n",
        "from pymongo import MongoClient\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import files\n",
        "from sklearn.cluster import KMeans, DBSCAN\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from datetime import datetime, timedelta\n",
        "# from scipy.stats import entropy\n",
        "\n",
        "# Provide the IP address, username, password, database name, RFC3339 standard time format, and create a connection client for the 'db0' database\n",
        "client = InfluxDBClient('59.120.114.133', 8086, 'telegraf', 'telegraf', 'db0', 'rfc3339', timeout=10)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to calculate start and end times for the previous day\n",
        "def calculate_previous_day_times():\n",
        "    current_datetime = datetime.now()\n",
        "    start_of_previous_day = current_datetime - timedelta(days=1)\n",
        "    start_of_previous_day = start_of_previous_day.replace(hour=0, minute=0, second=0, microsecond=0)\n",
        "    end_of_previous_day = current_datetime.replace(hour=0, minute=0, second=0, microsecond=0) - timedelta(microseconds=1)\n",
        "\n",
        "    return start_of_previous_day, end_of_previous_day"
      ],
      "metadata": {
        "id": "Ci3hctcSVjG4"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# InfluxDB query\n",
        "start_time, end_time = calculate_previous_day_times()\n",
        "\n",
        "sql_string = f'SELECT DISTINCT(\"value\") AS value FROM mbMQTT6 WHERE \"topic\" = \\'mbMQTT2/home2127/C2BDF8/TH20\\' AND time >= \\'{start_time.strftime(\"%Y-%m-%dT%H:%M:%SZ\")}\\' AND time <= \\'{end_time.strftime(\"%Y-%m-%dT%H:%M:%SZ\")}\\' GROUP BY time(10s) FILL(previous) ORDER BY time ASC TZ(\\'Asia/Taipei\\');'\n",
        "\n",
        "result = client.query(sql_string) #"
      ],
      "metadata": {
        "id": "sa2Ga-TsVkMr"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "homes_water_data = {\n",
        "    'home2127':pd.DataFrame(result['mbMQTT6']),\n",
        "    'home2128':pd.DataFrame(result['mbMQTT6'])\n",
        "}"
      ],
      "metadata": {
        "id": "yOchQnLpV0M7"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to fill missing values for a given home\n",
        "def fill_missing_values(home_data):\n",
        "    home_data['time'] = pd.to_datetime(home_data['time'])\n",
        "    home_data.set_index('time', inplace=True)\n",
        "    expected_time_intervals = pd.date_range(start=home_data.index.min(), end=home_data.index.max(), freq='10S')\n",
        "    home_data = home_data.reindex(expected_time_intervals)\n",
        "    home_data['value'] = home_data['value'].fillna(method='pad')\n",
        "    home_data.reset_index(inplace=True)\n",
        "    return home_data"
      ],
      "metadata": {
        "id": "OmNJ7-8yV0TG"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_home_data(home_water_df):\n",
        "    # Step 1: Fill missing values\n",
        "    filled_home_data = fill_missing_values(home_water_df)\n",
        "\n",
        "    # Step 2: Convert 'value' column to numeric and perform division and multiplication\n",
        "    filled_home_data['value'] = pd.to_numeric(filled_home_data['value'], errors='coerce')\n",
        "    filled_home_data['value'] = filled_home_data['value'] / 100000 * 1000\n",
        "\n",
        "    # Step 3: Calculate the difference between 'value' column\n",
        "    filled_home_data['volume'] = filled_home_data['value'].diff()\n",
        "\n",
        "    # Step 4: Replace NaN with 0 in the 'volume' column\n",
        "    filled_home_data['volume'] = filled_home_data['volume'].fillna(0)\n",
        "\n",
        "    # # Step 5: Filter values less than 0.2 in the 'volume' column\n",
        "    # filtered_home_data = filled_home_data[filled_home_data['volume'] < 0.2]\n",
        "    # Step 5: Filter values less than 0.2 in the 'volume' column and set them to 0\n",
        "    filled_home_data['volume'] = filled_home_data['volume'].apply(lambda x: 0 if x < 0.2 else x)\n",
        "\n",
        "    # Step 6: Rename 'index' column to 'time'\n",
        "    filled_home_data.reset_index(drop=True, inplace=True)\n",
        "    filled_home_data.rename(columns={'index': 'time'}, inplace=True)\n",
        "\n",
        "    # return filtered_home_data\n",
        "    return filled_home_data\n",
        "\n"
      ],
      "metadata": {
        "id": "quoPaJHXlCN2"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage for each home\n",
        "homes_data_processed = {}\n",
        "\n",
        "for home_name, home_water_df in homes_water_data.items():\n",
        "    processed_data = process_home_data(home_water_df)\n",
        "    homes_data_processed[home_name] = processed_data\n",
        "    # print(f\"\\nProcessed Data for {home_name}:\\n{processed_data}\")\n"
      ],
      "metadata": {
        "id": "Fuzgz55LlMmU"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import timedelta\n",
        "import numpy as np\n",
        "from scipy.stats import entropy\n",
        "\n",
        "def process_events(df):\n",
        "    start_time = None\n",
        "    end_time = None\n",
        "    consecutive_zeros = 0\n",
        "    total_time = timedelta()\n",
        "    total_vol = 0\n",
        "    num_records = 0\n",
        "\n",
        "     # Create a new DataFrame to store event information\n",
        "    event_df = pd.DataFrame(columns=['Start Time', 'End Time'])\n",
        "\n",
        "    for index, row in df.iterrows():\n",
        "        time = row['time']\n",
        "        vol = max(0, float(row['volume']))\n",
        "\n",
        "        if vol != 0:\n",
        "            if start_time is None:\n",
        "                start_time = time - timedelta(seconds=60)\n",
        "            consecutive_zeros = 0\n",
        "        else:\n",
        "            consecutive_zeros += 1\n",
        "            if start_time is not None and consecutive_zeros == 6:\n",
        "                end_time = time\n",
        "                # print(f\"Event start_time: {start_time}, end_time: {end_time}\")\n",
        "\n",
        "                # Filter volume values between start_time and end_time\n",
        "                event_data = df[(df['time'] >= start_time) & (df['time'] <= end_time)]\n",
        "\n",
        "                # Calculate total time, total volume, and coefficient of variation\n",
        "                time1 = start_time + timedelta(seconds=60)\n",
        "                time2 = end_time - timedelta(seconds=60)\n",
        "                event_data1 = df[(df['time'] >= time1) & (df['time'] <= time2)]\n",
        "\n",
        "                event_df = pd.concat([event_df, pd.DataFrame({\n",
        "                    'Start Time': [time1],\n",
        "                    'End Time': [time2],\n",
        "                })], ignore_index=True)\n",
        "\n",
        "                start_time = None  # Reset start_time for the next event\n",
        "\n",
        "    if event_df.empty:\n",
        "        print(\"No events detected.\")\n",
        "        return pd.DataFrame()  # Return an empty DataFrame if no events are detected\n",
        "\n",
        "    return event_df"
      ],
      "metadata": {
        "id": "_ZYS0tdACAj1"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_and_mark_usage(home_df):\n",
        "    # Process events\n",
        "    event_df = process_events(home_df)\n",
        "\n",
        "    # Calculate the duration of each event\n",
        "    event_df['Duration'] = (event_df['End Time'] - event_df['Start Time']).dt.total_seconds()\n",
        "\n",
        "    # Filter out events with zero duration\n",
        "    event_df = event_df[event_df['Duration'] != 0]\n",
        "\n",
        "    # Filter events with duration less than 10 seconds\n",
        "    event_atleast_10_df = event_df[event_df['Duration'] >= 10]\n",
        "\n",
        "    # Initialize 'usage' column in home_df\n",
        "    home_df['usage'] = 0\n",
        "\n",
        "    # Iterate through rows in event_atleast_10_df and mark corresponding rows in home_df as 1\n",
        "    for index, row in event_atleast_10_df.iterrows():\n",
        "        mask = (home_df['time'] >= row['Start Time']) & (home_df['time'] <= row['End Time'])\n",
        "        home_df.loc[mask, 'usage'] = 1\n",
        "\n",
        "    return home_df\n"
      ],
      "metadata": {
        "id": "b0I3Oq-xMl9U"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from pymongo import MongoClient\n",
        "\n",
        "def process_resample_insert(home_df, collection):\n",
        "    # Step 1: Process and mark usage\n",
        "    processed_home_df = process_and_mark_usage(home_df)\n",
        "    processed_home_df['time'] = pd.to_datetime(processed_home_df['time'])\n",
        "\n",
        "    # Step 2: Resample to 15-minute intervals and take max values within each interval\n",
        "    resampled_df = processed_home_df.set_index('time').resample('15T').max().reset_index()\n",
        "\n",
        "    # Step 3: Convert to dictionary and insert into MongoDB collection\n",
        "    data_dict = resampled_df.to_dict(orient='records')\n",
        "    collection.insert_many(data_dict)\n",
        "\n",
        "    return resampled_df\n",
        "\n"
      ],
      "metadata": {
        "id": "BNUOSVYUrLKH"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace 'your_database' and 'your_collection' with your actual database and collection names\n",
        "client = MongoClient('mongodb://34.81.144.96:27017/')\n",
        "db = client['Taipower']\n",
        "collection = db['SmartWaterMeterActiveHistory']"
      ],
      "metadata": {
        "id": "UzJ4gHikTC0K"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resampled_home_data = {}\n",
        "\n",
        "for home_name, filtered_renamed_home_data in homes_data_processed.items():\n",
        "    resampled_data = process_resample_insert(filtered_renamed_home_data, collection)\n",
        "    resampled_home_data[home_name] = resampled_data\n",
        "    print(f\"\\nResampled Data for {home_name}:\\n{resampled_data}\")\n"
      ],
      "metadata": {
        "id": "AVIqcFgPrQir",
        "outputId": "6f3ed9b2-06e9-4ea8-c249-eb24d732d02e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ServerSelectionTimeoutError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mServerSelectionTimeoutError\u001b[0m               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-406a0c724a68>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mhome_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltered_renamed_home_data\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhomes_data_processed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mresampled_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_resample_insert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_renamed_home_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mresampled_home_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhome_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresampled_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\nResampled Data for {home_name}:\\n{resampled_data}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-7bc92a26479c>\u001b[0m in \u001b[0;36mprocess_resample_insert\u001b[0;34m(home_df, collection)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# Step 3: Convert to dictionary and insert into MongoDB collection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mdata_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresampled_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'records'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mcollection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert_many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresampled_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pymongo/_csot.py\u001b[0m in \u001b[0;36mcsot_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0m_TimeoutContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcsot_wrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pymongo/collection.py\u001b[0m in \u001b[0;36minsert_many\u001b[0;34m(self, documents, ordered, bypass_document_validation, session, comment)\u001b[0m\n\u001b[1;32m    753\u001b[0m         \u001b[0mblk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Bulk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mordered\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbypass_document_validation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcomment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    754\u001b[0m         \u001b[0mblk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 755\u001b[0;31m         \u001b[0mblk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrite_concern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    756\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mInsertManyResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minserted_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrite_concern\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macknowledged\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pymongo/bulk.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, write_concern, session)\u001b[0m\n\u001b[1;32m    574\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 576\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrite_concern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pymongo/bulk.py\u001b[0m in \u001b[0;36mexecute_command\u001b[0;34m(self, generator, write_concern, session)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m         \u001b[0mclient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatabase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m         \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retryable_write\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_retryable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretryable_bulk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbulk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfull_result\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"writeErrors\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfull_result\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"writeConcernErrors\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pymongo/mongo_client.py\u001b[0m in \u001b[0;36m_retryable_write\u001b[0;34m(self, retryable, func, session, bulk)\u001b[0m\n\u001b[1;32m   1520\u001b[0m           \u001b[0;34m-\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mbulk\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbulk\u001b[0m \u001b[0mabstraction\u001b[0m \u001b[0mto\u001b[0m \u001b[0mexecute\u001b[0m \u001b[0moperations\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbulk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefaults\u001b[0m \u001b[0mto\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1521\u001b[0m         \"\"\"\n\u001b[0;32m-> 1522\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tmp_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1523\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retry_with_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretryable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbulk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't yield\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pymongo/mongo_client.py\u001b[0m in \u001b[0;36m_tmp_session\u001b[0;34m(self, session, close)\u001b[0m\n\u001b[1;32m   1838\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1839\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1840\u001b[0;31m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1841\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1842\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pymongo/mongo_client.py\u001b[0m in \u001b[0;36m_ensure_session\u001b[0;34m(self, session)\u001b[0m\n\u001b[1;32m   1821\u001b[0m             \u001b[0;31m# Don't make implicit sessions causally consistent. Applications\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1822\u001b[0m             \u001b[0;31m# should always opt-in.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1823\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__start_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcausal_consistency\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1824\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mConfigurationError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mInvalidOperation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1825\u001b[0m             \u001b[0;31m# Sessions not supported.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pymongo/mongo_client.py\u001b[0m in \u001b[0;36m__start_session\u001b[0;34m(self, implicit, **kwargs)\u001b[0m\n\u001b[1;32m   1764\u001b[0m         \u001b[0;31m# Raises ConfigurationError if sessions are not supported.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1765\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mimplicit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1766\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_topology\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_implicit_session_support\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1767\u001b[0m             \u001b[0mserver_session\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_EmptyServerSession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_ServerSession\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_EmptyServerSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1768\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pymongo/topology.py\u001b[0m in \u001b[0;36m_check_implicit_session_support\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    571\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_implicit_session_support\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 573\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_session_support\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    574\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_session_support\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pymongo/topology.py\u001b[0m in \u001b[0;36m_check_session_support\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    587\u001b[0m                     )\n\u001b[1;32m    588\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_description\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadable_servers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m                 self._select_servers_loop(\n\u001b[0m\u001b[1;32m    590\u001b[0m                     \u001b[0mreadable_server_selector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_server_selection_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pymongo/topology.py\u001b[0m in \u001b[0;36m_select_servers_loop\u001b[0;34m(self, selector, timeout, address)\u001b[0m\n\u001b[1;32m    257\u001b[0m             \u001b[0;31m# No suitable servers.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mnow\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mend_time\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m                 raise ServerSelectionTimeoutError(\n\u001b[0m\u001b[1;32m    260\u001b[0m                     \u001b[0;34mf\"{self._error_message(selector)}, Timeout: {timeout}s, Topology Description: {self.description!r}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m                 )\n",
            "\u001b[0;31mServerSelectionTimeoutError\u001b[0m: 34.81.144.96:27017: timed out (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms), Timeout: 30s, Topology Description: <TopologyDescription id: 65979d4236677ca956e276ea, topology_type: Unknown, servers: [<ServerDescription ('34.81.144.96', 27017) server_type: Unknown, rtt: None, error=NetworkTimeout('34.81.144.96:27017: timed out (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms)')>]>"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Repeat for additional home datasets as needed\n",
        "processed_home_df = {}\n",
        "resampled_df = {}\n",
        "data_dict = {}\n",
        "for home_name, filtered_renamed_home_data in homes_data_processed.items():\n",
        "  # Example usage for multiple home datasets\n",
        "  # home1_df = pd.read_csv(\"path/to/home1_data.csv\")\n",
        "  processed_home_df[home_name] = process_and_mark_usage(filtered_renamed_home_data)\n",
        "\n",
        "  processed_home_df[home_name]['time'] = pd.to_datetime(processed_home_df[home_name]['time'])  # Convert 'time' to datetime if not already\n",
        "\n",
        "  # Resample to 15-minute intervals and take the max values within each interval\n",
        "  resampled_df[home_name] = processed_home_df[home_name].set_index('time').resample('15T').max()\n",
        "\n",
        "  # Reset the index to make 'time' a regular column again\n",
        "  resampled_df[home_name] = resampled_df[home_name].reset_index()\n",
        "  data_dict[home_name] = resampled_df[home_name].to_dict(orient='records')\n",
        "\n",
        "  # # home2_df = pd.read_csv(\"path/to/home2_data.csv\")\n",
        "  # processed_home2_df = process_and_mark_usage(home2_df)\n",
        "  print(f\"\\n{data_dict}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-JeC1M-7M4nL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "waxxofPErG79"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "collection.insert_many(data_dict)"
      ],
      "metadata": {
        "id": "NbIdPEWZTG1q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(data_dict))"
      ],
      "metadata": {
        "id": "ZgcGQRzwW8hY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming 'data_dict' is your list of dictionaries\n",
        "result = collection.insert_many(data_dict)\n",
        "\n",
        "# Print the IDs of the inserted documents\n",
        "print(\"Inserted document IDs:\", result.inserted_ids)"
      ],
      "metadata": {
        "id": "tim_Zl5kWzTw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dict"
      ],
      "metadata": {
        "id": "D0uO6NM6OpMM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming homes_data is a dictionary where each value is a DataFrame for a specific home\n",
        "for home_name, filter_renamed_home_data in filtered_renamed_homes_data.items():\n",
        "    # Assuming event_atleast_20_df is also a dictionary with DataFrames for each home\n",
        "    if home_name in event_atleast_20_df:\n",
        "        # Iterate through rows in event_atleast_20_df and mark corresponding rows in df for the current home as 1\n",
        "        for index, row in event_atleast_20_df[home_name].iterrows():\n",
        "            mask = (filter_renamed_home_data['time'] >= row['Start Time']) & (filter_renamed_home_data['time'] <= row['End Time'])\n",
        "            filter_renamed_home_data.loc[mask, 'usage'] = 1\n",
        "\n",
        "# # Print or process the updated DataFrames (replace with your specific requirements)\n",
        "# for home_name, filter_renamed_home_data in filter_renamed_home_data.items():\n",
        "#     print(f\"\\nProcessed Data for {home_name} with Usage:\\n{filter_renamed_home_data}\")\n"
      ],
      "metadata": {
        "id": "dOAqor4MbTwM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: process events for all home data\n",
        "\n",
        "event_homes_data = {}\n",
        "for home_name, filtered_home_data in filtered_renamed_homes_data.items():\n",
        "    # Process events for each home\n",
        "    event_homes_data[home_name] = process_events(filtered_home_data)\n",
        "\n",
        "for home_name, event_home_data in event_homes_data.items():\n",
        "    print(f\"\\nEvent Data for {home_name}:\\n{event_home_data}\")"
      ],
      "metadata": {
        "id": "WS8U9T5rJhcS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: calculate the duration of each event\n",
        "event_atleast_20_df = {}\n",
        "for home_name, event_home_data in event_homes_data.items():\n",
        "    # Calculate the duration of each event\n",
        "    event_home_data['Duration'] = (event_home_data['End Time'] - event_home_data['Start Time']).dt.total_seconds() + 10\n",
        "    event_home_data = event_home_data[event_home_data['Duration'] != 10]\n",
        "    event_home_data['usage'] = 0\n",
        "\n",
        "\n",
        "    # Filter events with duration less than 20 seconds\n",
        "    event_atleast_20_df[home_name] = event_home_data[event_home_data['Duration'] >= 20]\n",
        "\n",
        "     # Reset index to clean up DataFrame\n",
        "    event_home_data.reset_index(drop=True, inplace=True)\n",
        "\n",
        "    if home_name in event_atleast_20_df:\n",
        "        # Iterate through rows in event_atleast_20_df and mark corresponding rows in df for the current home as 1\n",
        "        for index, row in event_atleast_20_df[home_name].iterrows():\n",
        "            mask = (filter_renamed_home_data['time'] >= row['Start Time']) & (filter_renamed_home_data['time'] <= row['End Time'])\n",
        "            filter_renamed_home_data.loc[mask, 'usage'] = 1\n",
        "\n",
        "    print(f\"\\n{filter_renamed_home_data}\")\n"
      ],
      "metadata": {
        "id": "IswuHufyJ90C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processed_home_df"
      ],
      "metadata": {
        "id": "y3kfLVImN6qk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "event_df = process_events(merged_df)\n",
        "\n",
        "# Calculate the duration of each event\n",
        "event_df['Duration'] = (event_df['End Time'] - event_df['Start Time']).dt.total_seconds()\n",
        "\n",
        "event_df = event_df[event_df['Duration'] != 0]\n",
        "\n",
        "# Filter events with duration less than 20 seconds\n",
        "event_atleast_20_df = event_df[event_df['Duration'] >= 10]\n",
        "\n",
        "# event_df = process_events(merged_df)\n",
        "merged_df['usage'] = 0\n",
        "\n",
        "# Iterate through rows in df1 and mark corresponding rows in df as 1\n",
        "for index, row in event_atleast_20_df.iterrows():\n",
        "    mask = (merged_df['time'] >= row['Start Time']) & (merged_df['time'] <= row['End Time'])\n",
        "    merged_df.loc[mask, 'usage'] = 1\n",
        "\n",
        "vol_df = merged_df[['time', 'volume_liters']].copy()\n",
        "usage_df = merged_df[['time', 'usage']].copy()\n",
        "\n",
        "usage_df.set_index('time', inplace=True)# Set 'time' as the index\n",
        "vol_df.set_index('time', inplace=True)# Set 'time' as the index"
      ],
      "metadata": {
        "id": "Nt-BZ8O1JduN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}