{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNJV3BHYfqFmaVbUP1cR5yt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bhekmuzi/water-usage-norm/blob/main/src/data_retrieval.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip freeze > requirements.txt"
      ],
      "metadata": {
        "id": "tn2hJoUBYdoc"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install influxdb"
      ],
      "metadata": {
        "id": "N-bFSmf9YmhF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas pymongo"
      ],
      "metadata": {
        "id": "uzwCwKVcZPC4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "qih7MD7MTfH8"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.cluster import KMeans\n",
        "# pip install influxdb\n",
        "# !python --version\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import datetime\n",
        "import time\n",
        "from influxdb import InfluxDBClient\n",
        "from pymongo import MongoClient\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import files\n",
        "from sklearn.cluster import KMeans, DBSCAN\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from datetime import datetime, timedelta\n",
        "# from scipy.stats import entropy\n",
        "\n",
        "# Provide the IP address, username, password, database name, RFC3339 standard time format, and create a connection client for the 'db0' database\n",
        "client = InfluxDBClient('59.120.114.133', 8086, 'telegraf', 'telegraf', 'db0', 'rfc3339', timeout=10)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to calculate start and end times for the previous day\n",
        "def calculate_previous_day_times():\n",
        "    current_datetime = datetime.now()\n",
        "    start_of_previous_day = current_datetime - timedelta(days=1)\n",
        "    start_of_previous_day = start_of_previous_day.replace(hour=0, minute=0, second=0, microsecond=0)\n",
        "    end_of_previous_day = current_datetime.replace(hour=0, minute=0, second=0, microsecond=0) - timedelta(microseconds=1)\n",
        "\n",
        "    return start_of_previous_day, end_of_previous_day"
      ],
      "metadata": {
        "id": "Ci3hctcSVjG4"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# InfluxDB query\n",
        "start_time, end_time = calculate_previous_day_times()\n",
        "\n",
        "sql_string = f'SELECT DISTINCT(\"value\") AS value FROM mbMQTT6 WHERE \"topic\" = \\'mbMQTT2/home2127/C2BDF8/TH20\\' AND time >= \\'{start_time.strftime(\"%Y-%m-%dT%H:%M:%SZ\")}\\' AND time <= \\'{end_time.strftime(\"%Y-%m-%dT%H:%M:%SZ\")}\\' GROUP BY time(10s) FILL(previous) ORDER BY time ASC TZ(\\'Asia/Taipei\\');'\n",
        "\n",
        "result = client.query(sql_string) #"
      ],
      "metadata": {
        "id": "sa2Ga-TsVkMr"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "homes_water_data = {\n",
        "    'home2127':pd.DataFrame(result['mbMQTT6']),\n",
        "    'home2128':pd.DataFrame(result['mbMQTT6'])\n",
        "}"
      ],
      "metadata": {
        "id": "yOchQnLpV0M7"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to fill missing values for a given home\n",
        "def fill_missing_values(home_data):\n",
        "    home_data['time'] = pd.to_datetime(home_data['time'])\n",
        "    home_data.set_index('time', inplace=True)\n",
        "    expected_time_intervals = pd.date_range(start=home_data.index.min(), end=home_data.index.max(), freq='10S')\n",
        "    home_data = home_data.reindex(expected_time_intervals)\n",
        "    home_data['value'] = home_data['value'].fillna(method='pad')\n",
        "    home_data.reset_index(inplace=True)\n",
        "    return home_data"
      ],
      "metadata": {
        "id": "OmNJ7-8yV0TG"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_home_data(home_water_df):\n",
        "    # Step 1: Fill missing values\n",
        "    filled_home_data = fill_missing_values(home_water_df)\n",
        "\n",
        "    # Step 2: Convert 'value' column to numeric and perform division and multiplication\n",
        "    filled_home_data['value'] = pd.to_numeric(filled_home_data['value'], errors='coerce')\n",
        "    filled_home_data['value'] = filled_home_data['value'] / 100000 * 1000\n",
        "\n",
        "    # Step 3: Calculate the difference between 'value' column\n",
        "    filled_home_data['volume'] = filled_home_data['value'].diff()\n",
        "\n",
        "    # Step 4: Replace NaN with 0 in the 'volume' column\n",
        "    filled_home_data['volume'] = filled_home_data['volume'].fillna(0)\n",
        "\n",
        "    # # Step 5: Filter values less than 0.2 in the 'volume' column\n",
        "    # filtered_home_data = filled_home_data[filled_home_data['volume'] < 0.2]\n",
        "    # Step 5: Filter values less than 0.2 in the 'volume' column and set them to 0\n",
        "    filled_home_data['volume'] = filled_home_data['volume'].apply(lambda x: 0 if x < 0.2 else x)\n",
        "\n",
        "    # Step 6: Rename 'index' column to 'time'\n",
        "    filled_home_data.reset_index(drop=True, inplace=True)\n",
        "    filled_home_data.rename(columns={'index': 'time'}, inplace=True)\n",
        "\n",
        "    # return filtered_home_data\n",
        "    return filled_home_data\n",
        "\n"
      ],
      "metadata": {
        "id": "quoPaJHXlCN2"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage for each home\n",
        "homes_data_processed = {}\n",
        "\n",
        "for home_name, home_water_df in homes_water_data.items():\n",
        "    processed_data = process_home_data(home_water_df)\n",
        "    homes_data_processed[home_name] = processed_data\n",
        "    # print(f\"\\nProcessed Data for {home_name}:\\n{processed_data}\")\n"
      ],
      "metadata": {
        "id": "Fuzgz55LlMmU"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import timedelta\n",
        "import numpy as np\n",
        "from scipy.stats import entropy\n",
        "\n",
        "def process_events(df):\n",
        "    start_time = None\n",
        "    end_time = None\n",
        "    consecutive_zeros = 0\n",
        "    total_time = timedelta()\n",
        "    total_vol = 0\n",
        "    num_records = 0\n",
        "\n",
        "     # Create a new DataFrame to store event information\n",
        "    event_df = pd.DataFrame(columns=['Start Time', 'End Time'])\n",
        "\n",
        "    for index, row in df.iterrows():\n",
        "        time = row['time']\n",
        "        vol = max(0, float(row['volume']))\n",
        "\n",
        "        if vol != 0:\n",
        "            if start_time is None:\n",
        "                start_time = time - timedelta(seconds=60)\n",
        "            consecutive_zeros = 0\n",
        "        else:\n",
        "            consecutive_zeros += 1\n",
        "            if start_time is not None and consecutive_zeros == 6:\n",
        "                end_time = time\n",
        "                # print(f\"Event start_time: {start_time}, end_time: {end_time}\")\n",
        "\n",
        "                # Filter volume values between start_time and end_time\n",
        "                event_data = df[(df['time'] >= start_time) & (df['time'] <= end_time)]\n",
        "\n",
        "                # Calculate total time, total volume, and coefficient of variation\n",
        "                time1 = start_time + timedelta(seconds=60)\n",
        "                time2 = end_time - timedelta(seconds=60)\n",
        "                event_data1 = df[(df['time'] >= time1) & (df['time'] <= time2)]\n",
        "\n",
        "                event_df = pd.concat([event_df, pd.DataFrame({\n",
        "                    'Start Time': [time1],\n",
        "                    'End Time': [time2],\n",
        "                })], ignore_index=True)\n",
        "\n",
        "                start_time = None  # Reset start_time for the next event\n",
        "\n",
        "    if event_df.empty:\n",
        "        print(\"No events detected.\")\n",
        "        return pd.DataFrame()  # Return an empty DataFrame if no events are detected\n",
        "\n",
        "    return event_df"
      ],
      "metadata": {
        "id": "_ZYS0tdACAj1"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_and_mark_usage(home_df):\n",
        "    # Process events\n",
        "    event_df = process_events(home_df)\n",
        "\n",
        "    # Calculate the duration of each event\n",
        "    event_df['Duration'] = (event_df['End Time'] - event_df['Start Time']).dt.total_seconds()\n",
        "\n",
        "    # Filter out events with zero duration\n",
        "    event_df = event_df[event_df['Duration'] != 0]\n",
        "\n",
        "    # Filter events with duration less than 10 seconds\n",
        "    event_atleast_10_df = event_df[event_df['Duration'] >= 10]\n",
        "\n",
        "    # Initialize 'usage' column in home_df\n",
        "    home_df['usage'] = 0\n",
        "\n",
        "    # Iterate through rows in event_atleast_10_df and mark corresponding rows in home_df as 1\n",
        "    for index, row in event_atleast_10_df.iterrows():\n",
        "        mask = (home_df['time'] >= row['Start Time']) & (home_df['time'] <= row['End Time'])\n",
        "        home_df.loc[mask, 'usage'] = 1\n",
        "\n",
        "    return home_df\n"
      ],
      "metadata": {
        "id": "b0I3Oq-xMl9U"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from pymongo import MongoClient\n",
        "import json\n",
        "\n",
        "def process_resample_insert(home_df, home_id):\n",
        "    # Step 1: Process and mark usage\n",
        "    processed_home_df = process_and_mark_usage(home_df)\n",
        "    processed_home_df['time'] = pd.to_datetime(processed_home_df['time'])\n",
        "\n",
        "    # Step 2: Resample to 15-minute intervals and take max values within each interval\n",
        "    resampled_df = processed_home_df.set_index('time').resample('15T').max().reset_index()\n",
        "\n",
        "    # Extract the date and add it as a new column\n",
        "    resampled_df['date'] = resampled_df['time'].dt.date\n",
        "\n",
        "    # Drop the 'value' column\n",
        "    resampled_df = resampled_df.drop(columns=['value', 'time', 'volume'])\n",
        "\n",
        "    # Calculate active_score\n",
        "    active_score = round(resampled_df[\"usage\"].sum() / 96 * 100, 3)\n",
        "\n",
        "    # Group by 'date' and aggregate 'usage' column as a list\n",
        "    grouped_df = resampled_df.groupby('date')['usage'].apply(list).reset_index()\n",
        "\n",
        "    # Group by 'date' and aggregate 'usage' column as a list\n",
        "    grouped_df = resampled_df.groupby('date')['usage'].apply(list).reset_index()\n",
        "\n",
        "    # Convert DataFrame to a dictionary\n",
        "    result_dict = {}\n",
        "\n",
        "    # load date, homeid, usage, and active_score into a json variable result_json\n",
        "\n",
        "    for index, row in grouped_df.iterrows():\n",
        "        # result_dict[row['date']] = {\n",
        "        result_dict = {\n",
        "            'date': row['date'],\n",
        "            'homeID': home_id,\n",
        "            'usage': row['usage'],\n",
        "            'active_score': active_score\n",
        "        }\n",
        "\n",
        "    return result_dict\n",
        "\n",
        "# Example usage of the function\n",
        "resampled_home_data = {}\n",
        "\n",
        "for home_name, filtered_renamed_home_data in homes_data_processed.items():\n",
        "    resampled_data = process_resample_insert(filtered_renamed_home_data, home_name)\n",
        "    resampled_home_data[home_name] = resampled_data\n",
        "    print(f\"\\nResampled Data for {home_name}:\\n{resampled_data}\")"
      ],
      "metadata": {
        "id": "_taRS8mMjVJH",
        "outputId": "902da508-a938-441a-c66f-20aa16b6bddf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Resampled Data for home2127:\n",
            "{'date': datetime.date(2024, 1, 14), 'homeID': 'home2127', 'usage': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0], 'active_score': 18.75}\n",
            "\n",
            "Resampled Data for home2128:\n",
            "{'date': datetime.date(2024, 1, 14), 'homeID': 'home2128', 'usage': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0], 'active_score': 18.75}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from pymongo import MongoClient\n",
        "import json\n",
        "\n",
        "def process_resample_insert(home_df, home_id):\n",
        "    # Step 1: Process and mark usage\n",
        "    processed_home_df = process_and_mark_usage(home_df)\n",
        "    processed_home_df['time'] = pd.to_datetime(processed_home_df['time'])\n",
        "\n",
        "    # Step 2: Resample to 15-minute intervals and take max values within each interval\n",
        "    resampled_df = processed_home_df.set_index('time').resample('15T').max().reset_index()\n",
        "\n",
        "    # Extract the date and add it as a new column\n",
        "    resampled_df['date'] = resampled_df['time'].dt.date\n",
        "\n",
        "    # Drop the 'value' column\n",
        "    resampled_df = resampled_df.drop(columns=['value', 'time', 'volume'])\n",
        "\n",
        "    # Calculate active_score\n",
        "    active_score = round(resampled_df[\"usage\"].sum() / 96 * 100, 3)\n",
        "\n",
        "    # Group by 'date' and aggregate 'usage' column as a list\n",
        "    grouped_df = resampled_df.groupby('date')['usage'].apply(list).reset_index()\n",
        "\n",
        "    # Convert DataFrame to a dictionary\n",
        "    result_dict = {\n",
        "        'date': grouped_df['date'].tolist(),\n",
        "        'homeID': home_id,\n",
        "        'usage': grouped_df['usage'].tolist(),\n",
        "        'active_score': [active_score] * len(grouped_df)\n",
        "    }\n",
        "\n",
        "    return result_dict\n",
        "\n",
        "# Example usage of the function\n",
        "resampled_home_data = {}\n",
        "\n",
        "for home_name, filtered_renamed_home_data in homes_data_processed.items():\n",
        "    resampled_data = process_resample_insert(filtered_renamed_home_data, home_name)\n",
        "    resampled_home_data[home_name] = resampled_data\n",
        "    print(f\"\\nResampled Data for {home_name}:\\n{resampled_data}\")\n"
      ],
      "metadata": {
        "id": "TUyLwshPvjsm",
        "outputId": "b35d0e2c-6fdd-4f46-faf7-184d382809f0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Resampled Data for home2127:\n",
            "{'date': [datetime.date(2024, 1, 14)], 'homeID': 'home2127', 'usage': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0]], 'active_score': [18.75]}\n",
            "\n",
            "Resampled Data for home2128:\n",
            "{'date': [datetime.date(2024, 1, 14)], 'homeID': 'home2128', 'usage': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0]], 'active_score': [18.75]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# Replace 'your_database' and 'your_collection' with your actual database and collection names\n",
        "client = MongoClient('mongodb://34.81.144.96:27017/')\n",
        "db = client['Taipower']\n",
        "collection = db['SmartWaterMeterActiveHistory']\n",
        "\n",
        "# json.loads(resampled_home_data)\n",
        "\n",
        "\n",
        "# Insert the resampled_home_data into the MongoDB collection\n",
        "for home_name, resampled_data in resampled_home_data.items():\n",
        "    for date, data in resampled_data.items():\n",
        "        collection.insert_one(data)\n",
        "\n",
        "# Close the MongoDB connection\n",
        "client.close()"
      ],
      "metadata": {
        "id": "UzJ4gHikTC0K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage of the function\n",
        "resampled_home_data = {}\n",
        "\n",
        "for home_name, filtered_renamed_home_data in homes_data_processed.items():\n",
        "    resampled_data = process_resample_insert(filtered_renamed_home_data, home_name)\n",
        "    resampled_home_data[home_name] = resampled_data\n",
        "\n",
        "    # Insert the data into MongoDB\n",
        "    collection.insert_one(resampled_data)\n",
        "\n",
        "    print(f\"\\nResampled Data for {home_name}:\\n{resampled_data}\")"
      ],
      "metadata": {
        "id": "P8Uw2x6yBnh6",
        "outputId": "cdcdac66-7052-46b4-d47d-b9ebda991048",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ServerSelectionTimeoutError",
          "evalue": "34.81.144.96:27017: timed out (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms), Timeout: 30s, Topology Description: <TopologyDescription id: 65a49c92844a5946ca7c1766, topology_type: Unknown, servers: [<ServerDescription ('34.81.144.96', 27017) server_type: Unknown, rtt: None, error=NetworkTimeout('34.81.144.96:27017: timed out (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms)')>]>",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mServerSelectionTimeoutError\u001b[0m               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-45cee0029ccf>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# Insert the data into MongoDB\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mcollection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert_one\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresampled_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\nResampled Data for {home_name}:\\n{resampled_data}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pymongo/collection.py\u001b[0m in \u001b[0;36minsert_one\u001b[0;34m(self, document, bypass_document_validation, session, comment)\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0mwrite_concern\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_write_concern_for\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m         return InsertOneResult(\n\u001b[0;32m--> 669\u001b[0;31m             self._insert_one(\n\u001b[0m\u001b[1;32m    670\u001b[0m                 \u001b[0mdocument\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m                 \u001b[0mordered\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pymongo/collection.py\u001b[0m in \u001b[0;36m_insert_one\u001b[0;34m(self, doc, ordered, write_concern, op_id, bypass_doc_val, session, comment)\u001b[0m\n\u001b[1;32m    607\u001b[0m             \u001b[0m_check_write_command_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    608\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 609\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__database\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retryable_write\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macknowledged\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_insert_command\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    610\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRawBSONDocument\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pymongo/mongo_client.py\u001b[0m in \u001b[0;36m_retryable_write\u001b[0;34m(self, retryable, func, session, bulk)\u001b[0m\n\u001b[1;32m   1520\u001b[0m           \u001b[0;34m-\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mbulk\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbulk\u001b[0m \u001b[0mabstraction\u001b[0m \u001b[0mto\u001b[0m \u001b[0mexecute\u001b[0m \u001b[0moperations\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbulk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefaults\u001b[0m \u001b[0mto\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1521\u001b[0m         \"\"\"\n\u001b[0;32m-> 1522\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tmp_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1523\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retry_with_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretryable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbulk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't yield\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pymongo/mongo_client.py\u001b[0m in \u001b[0;36m_tmp_session\u001b[0;34m(self, session, close)\u001b[0m\n\u001b[1;32m   1838\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1839\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1840\u001b[0;31m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1841\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1842\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pymongo/mongo_client.py\u001b[0m in \u001b[0;36m_ensure_session\u001b[0;34m(self, session)\u001b[0m\n\u001b[1;32m   1821\u001b[0m             \u001b[0;31m# Don't make implicit sessions causally consistent. Applications\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1822\u001b[0m             \u001b[0;31m# should always opt-in.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1823\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__start_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcausal_consistency\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1824\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mConfigurationError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mInvalidOperation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1825\u001b[0m             \u001b[0;31m# Sessions not supported.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pymongo/mongo_client.py\u001b[0m in \u001b[0;36m__start_session\u001b[0;34m(self, implicit, **kwargs)\u001b[0m\n\u001b[1;32m   1764\u001b[0m         \u001b[0;31m# Raises ConfigurationError if sessions are not supported.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1765\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mimplicit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1766\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_topology\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_implicit_session_support\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1767\u001b[0m             \u001b[0mserver_session\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_EmptyServerSession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_ServerSession\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_EmptyServerSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1768\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pymongo/topology.py\u001b[0m in \u001b[0;36m_check_implicit_session_support\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    571\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_implicit_session_support\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 573\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_session_support\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    574\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_session_support\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pymongo/topology.py\u001b[0m in \u001b[0;36m_check_session_support\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    587\u001b[0m                     )\n\u001b[1;32m    588\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_description\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadable_servers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m                 self._select_servers_loop(\n\u001b[0m\u001b[1;32m    590\u001b[0m                     \u001b[0mreadable_server_selector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_server_selection_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pymongo/topology.py\u001b[0m in \u001b[0;36m_select_servers_loop\u001b[0;34m(self, selector, timeout, address)\u001b[0m\n\u001b[1;32m    257\u001b[0m             \u001b[0;31m# No suitable servers.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mnow\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mend_time\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m                 raise ServerSelectionTimeoutError(\n\u001b[0m\u001b[1;32m    260\u001b[0m                     \u001b[0;34mf\"{self._error_message(selector)}, Timeout: {timeout}s, Topology Description: {self.description!r}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m                 )\n",
            "\u001b[0;31mServerSelectionTimeoutError\u001b[0m: 34.81.144.96:27017: timed out (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms), Timeout: 30s, Topology Description: <TopologyDescription id: 65a49c92844a5946ca7c1766, topology_type: Unknown, servers: [<ServerDescription ('34.81.144.96', 27017) server_type: Unknown, rtt: None, error=NetworkTimeout('34.81.144.96:27017: timed out (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms)')>]>"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Query data from mongodb\n",
        "\n",
        "# print(db.list_collection_names())\n",
        "# client.close()\n",
        "# Specify the homeid you want to query\n",
        "homeid = \"Home2127\"\n",
        "\n",
        "# Calculate the date of the previous day\n",
        "end_date = datetime.now()\n",
        "start_date  = (datetime.now() - timedelta(days=7))\n",
        "\n",
        "# Query for documents with the specified homeid\n",
        "query = {\n",
        "    \"home_id\": homeid,\n",
        "    \"date\": {\"$gte\": start_date.strftime('%Y-%m-%d'),\n",
        "             \"$lte\": end_date.strftime('%Y-%m-%d')}\n",
        "}\n",
        "# query = {\"home_id\": homeid, \"date\": previous_day}\n",
        "result = collection.find(query)\n",
        "\n",
        "# Print the results\n",
        "for document in result:\n",
        "    print(document)\n",
        "\n",
        "# Close the connection\n",
        "client.close()"
      ],
      "metadata": {
        "id": "JxWmdWUqkykT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert dictionary back to usable data\n"
      ],
      "metadata": {
        "id": "mvqDKu9buYAw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate active scores, Norms, and correlation coefficient\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "def calculate_metrics(input_df):\n",
        "    # Sum the columns\n",
        "    norm_sum = input_df.sum()\n",
        "\n",
        "    # Calculate active score\n",
        "    active_score = input_df.sum() / (len(input_df) * len(input_df.columns)) * 100\n",
        "\n",
        "    # Sort DataFrame in ascending order by the first column\n",
        "    sorted_df = input_df.sort_values(by=input_df.columns[0], ascending=True)\n",
        "\n",
        "    # Find the index to split the DataFrame into two halves\n",
        "    split_index = len(sorted_df) // 2\n",
        "\n",
        "    # Split the DataFrame into the first and second halves\n",
        "    first_half = sorted_df.iloc[:split_index, :]\n",
        "    second_half = sorted_df.iloc[split_index:, :]\n",
        "\n",
        "    # Calculate the averages for each half\n",
        "    low_norm = first_half.mean()\n",
        "    high_norm = second_half.mean()\n",
        "\n",
        "    # Calculate overall norm\n",
        "    overall_norm = sorted_df.mean()\n",
        "\n",
        "    return {\n",
        "        'active_score': active_score,\n",
        "        'low_norm': low_norm,\n",
        "        'norm': overall_norm,\n",
        "        'high_norm': high_norm\n",
        "    }\n",
        "\n",
        "# Example usage\n",
        "# Assuming 'two_week_norm' is your DataFrame\n",
        "result = calculate_metrics(two_week_norm)\n",
        "\n",
        "# Print the result\n",
        "print(result)\n"
      ],
      "metadata": {
        "id": "Vk5FYduquklq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "age = [30, 20, 52, 85, 6]\n",
        "# Simulating receiving JSON data from Golang\n",
        "golang_json_data = '{\"name\": \"John Doe\", \"age\": ' + json.dumps(age) + ', \"city\": \"Example City\", \"email\": \"john@example.com\"}'\n",
        "\n",
        "# Deserialize JSON data in Python\n",
        "python_data = json.loads(golang_json_data)\n",
        "\n",
        "print(\"Python Data:\", python_data)\n"
      ],
      "metadata": {
        "id": "__uJdSwJ3KnS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}